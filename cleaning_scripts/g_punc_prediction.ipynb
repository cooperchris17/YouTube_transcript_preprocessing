{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this version, all of the punctuation predicted by the model is restored\n",
    "#### but the hyphens and colons are replaced with commas\n",
    "##### https://pypi.org/project/deepmultilingualpunctuation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepmultilingualpunctuation in c:\\users\\coope\\anaconda3\\lib\\site-packages (1.0.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torch>=1.8.1 in c:\\users\\coope\\anaconda3\\lib\\site-packages (from deepmultilingualpunctuation) (1.10.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\coope\\anaconda3\\lib\\site-packages (from deepmultilingualpunctuation) (4.16.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\coope\\anaconda3\\lib\\site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.7.4.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in c:\\users\\coope\\anaconda3\\lib\\site-packages (from transformers->deepmultilingualpunctuation) (0.11.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\coope\\anaconda3\\lib\\site-packages (from transformers->deepmultilingualpunctuation) (20.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\coope\\anaconda3\\lib\\site-packages (from transformers->deepmultilingualpunctuation) (5.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\coope\\anaconda3\\lib\\site-packages (from transformers->deepmultilingualpunctuation) (2020.10.15)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\coope\\anaconda3\\lib\\site-packages (from transformers->deepmultilingualpunctuation) (0.0.47)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\coope\\anaconda3\\lib\\site-packages (from transformers->deepmultilingualpunctuation) (1.19.2)\n",
      "Requirement already satisfied: requests in c:\\users\\coope\\anaconda3\\lib\\site-packages (from transformers->deepmultilingualpunctuation) (2.24.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\coope\\anaconda3\\lib\\site-packages (from transformers->deepmultilingualpunctuation) (4.50.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\coope\\anaconda3\\lib\\site-packages (from transformers->deepmultilingualpunctuation) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\coope\\anaconda3\\lib\\site-packages (from transformers->deepmultilingualpunctuation) (0.4.0)\n",
      "Requirement already satisfied: six in c:\\users\\coope\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers->deepmultilingualpunctuation) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\coope\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers->deepmultilingualpunctuation) (2.4.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\coope\\anaconda3\\lib\\site-packages (from sacremoses->transformers->deepmultilingualpunctuation) (0.17.0)\n",
      "Requirement already satisfied: click in c:\\users\\coope\\anaconda3\\lib\\site-packages (from sacremoses->transformers->deepmultilingualpunctuation) (7.1.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\coope\\anaconda3\\lib\\site-packages (from requests->transformers->deepmultilingualpunctuation) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\coope\\anaconda3\\lib\\site-packages (from requests->transformers->deepmultilingualpunctuation) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\coope\\anaconda3\\lib\\site-packages (from requests->transformers->deepmultilingualpunctuation) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\coope\\anaconda3\\lib\\site-packages (from requests->transformers->deepmultilingualpunctuation) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "pip install deepmultilingualpunctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load the necessary libraries\n",
    "##### you need to install transformers for the model to work\n",
    "##### see e.g. https://huggingface.co/docs/transformers/installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coope\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:135: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.NONE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "from deepmultilingualpunctuation import PunctuationModel\n",
    "\n",
    "model = PunctuationModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For every .txt file in the folder or any subfolders\n",
    "##### All punctuation predicted by the model will be restored\n",
    "##### This script will overwrite the files (so it's good to have a backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.iglob('**', recursive=True):\n",
    "    # if the file is a file (not a directory)\n",
    "    if os.path.isfile(file):\n",
    "        # avoid editing .py files, etc\n",
    "        if file.endswith('.txt'):\n",
    "            with open(file, 'r') as input:\n",
    "                text = input.read()\n",
    "                \n",
    "                clean_text = model.preprocess(text)\n",
    "                # this generates a list of lists ['word', 'punctuation or 0 for no punctuation', 'probability']\n",
    "                labeled_words = model.predict(clean_text)\n",
    "                \n",
    "                # create an empty list for the new text\n",
    "                new_text = []\n",
    "                \n",
    "                for item in labeled_words:        \n",
    "                    # if the model predicts no punctuation, just add the word\n",
    "                    if item[1] == '0':\n",
    "                        # https://community.dataquest.io/t/using-the-append-method-with-two-arguments/515619\n",
    "                        # only one argument, so I can use .append in the normal way\n",
    "                        new_text.append(item[0])\n",
    "                    # if the model predicts a full stop, add the word and the full stop to the new text (same for other punctuation)\n",
    "                    if item[1] == '.':\n",
    "                        # two arguments, so I need to use .extend and add a list of 2 items (if I use append, I will get a list within the list)\n",
    "                        new_text.extend([item[0], item[1]])\n",
    "                    if item[1] == '?':\n",
    "                        new_text.extend([item[0], item[1]])\n",
    "                    if item[1] == ',':\n",
    "                        new_text.extend([item[0], item[1]])\n",
    "                    # for colons and hyphens, add a comma (not the predicted punctuation 'item[1]')\n",
    "                    if item[1] == ':':\n",
    "                        new_text.extend([item[0], ','])\n",
    "                    if item[1] == '-':\n",
    "                        new_text.extend([item[0], ','])\n",
    "\n",
    "            # https://stackoverflow.com/questions/15950672/join-split-words-and-punctuation-with-punctuation-in-the-right-place\n",
    "            punc = set(',.?') # or whatever special chars you want\n",
    "\n",
    "            with open('temp.txt', 'w') as output:\n",
    "                # join punctuation to the previous word and all other words by a space\n",
    "                output.write(''.join(w if set(w) <= punc else ' '+w for w in new_text).lstrip())\n",
    "            os.replace('temp.txt', file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
